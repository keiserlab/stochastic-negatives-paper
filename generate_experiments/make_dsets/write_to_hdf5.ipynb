{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Purpose: generate data for use with training neural networks. DM and PCBA scrubbed'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__author__ = \"Elena Caceres\"\n",
    "__email__ = \"ecaceres@keiserlab.org\"\n",
    "\"\"\"Purpose: generate data for use with training neural networks. DM and PCBA scrubbed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import argparse\n",
    "import h5py\n",
    "import cPickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.stats import mode\n",
    "from common.data_converter import convert_to_pki\n",
    "np.random.seed(42)\n",
    "\n",
    "def get_env_var(handle):\n",
    "    tmp = os.getenv(handle)\n",
    "    if not tmp:\n",
    "        raise LookupError(\"Environment variable: {} not set.\".format(handle))\n",
    "    return tmp.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_mol_pairs(chembl):\n",
    "    # for ChEMBL\n",
    "    unique_pairs = set()\n",
    "    with gzip.open(chembl, \"rb\") as f:\n",
    "        a = f.next()\n",
    "        vals = a.split(\"\\t\")\n",
    "        print(\"{}: {}\".format(vals[2], vals[3]))\n",
    "        for line in f:\n",
    "            # tid:mid\n",
    "            unique_pairs.update({(line.split(\"\\t\")[2], line.split(\"\\t\")[3])})\n",
    "\n",
    "    return unique_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = get_env_var(\"DATA_SAVE_BASE\")\n",
    "expt_base = \"{}/20180525_DM_scrubbing/train_data\".format(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of total tid, mid pairs: 709614\r\n",
      "Bad training cases removed: 22018\r\n",
      "current fcn: one mol one target\r\n",
      "Training Cases: 687596\r\n",
      "Fingerprint Length: 4096\r\n",
      "Number of Targets: 2326\r\n",
      "current fcn: one mol many target\r\n",
      "Training Cases: 1\r\n",
      "Fingerprint Length: 4096\r\n",
      "Number of Targets: 2326\r\n"
     ]
    }
   ],
   "source": [
    "# load inchi:mid map\n",
    "print(\"loading inchi to mid\")\n",
    "with gzip.open(inchi_map, \"rb\") as f:\n",
    "    # store molecules in case we want to go back and look them up.\n",
    "    ikey_map = pkl.load(f)\n",
    "ikey_map = ikey_map.set_index(\"index\").to_dict()[0]\n",
    "\n",
    "# load fingerprints:ikey file\n",
    "fp = \"\"\n",
    "fp_lookup_dict={ikey_map[i] : np.zeros((fp_len,), dtype=bool) for i in ikey_map.keys()}\n",
    "with gzip.open(fp_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        fp, ikey = line.rstrip().split(\"\\t\")\n",
    "        fp_lookup_dict.update({ikey: np.array(map(int, fp), dtype=bool)})\n",
    "assert(fp_len == len(np.array(map(int, fp), dtype=bool)))\n",
    "\n",
    "print(\"Fingerprint length: {}\".format(fp_len))\n",
    "\n",
    "target_mol_pairs = get_target_mol_pairs(chembl_data)\n",
    "\n",
    "unique_pairs = set()\n",
    "for tid, mid in target_mol_pairs:\n",
    "    try:\n",
    "        unique_pairs.update({(tid, ikey_map[mid])})\n",
    "    except KeyError:\n",
    "        print(\"Skipping MID {} for target {}. Not in INCHI lookup\".format(mid, tid))\n",
    "\n",
    "print(\"Length of total tid, mid pairs: {}\".format(len(unique_pairs)))\n",
    "\n",
    "# number of unique molecules/target on on a target basis\n",
    "targets_counts = defaultdict(int)\n",
    "for pair in unique_pairs:\n",
    "    targets_counts[pair[0]] += 1\n",
    "\n",
    "# Get a list of (target, molecule) pairs where the number of unique molecules surpasses 9\n",
    "# Re-open our original dataset and get a list of tuples of all (values, relation, doc_id, year) for our data\n",
    "all_data = {}\n",
    "unique_ikey_smiles = {}\n",
    "values = []\n",
    "# get chembl data\n",
    "with gzip.open(chembl_data, \"rb\") as f:\n",
    "    f.next()\n",
    "    for line in f:\n",
    "        doc_id, year, tid, mid, pref_name, act, rel, smi = line.split(\"\\t\")\n",
    "        try:\n",
    "            ikey = ikey_map[mid]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if (tid, ikey) in unique_pairs:\n",
    "            if rel == '>':\n",
    "                act = float(act)\n",
    "                orig_act = act\n",
    "                # convert to log space\n",
    "                act = -np.log10(act) + 9\n",
    "                # add 2-3 logs\n",
    "                act -= np.random.uniform(2.0, 3.0)\n",
    "                if act <= 0:\n",
    "                    # we're in positive space here, people! can't have a negative, that would be madness.\n",
    "                    if -act > orig_act:\n",
    "                        act = orig_act\n",
    "                    else:\n",
    "                        act = -act\n",
    "                # and then convert it back to nM space\n",
    "                act = 10 ** (-(act - 9))\n",
    "            if (tid, ikey) in all_data:\n",
    "                try:\n",
    "                    all_data[(tid, ikey)].append((int(doc_id), int(year), float(act), rel))\n",
    "                    values.append(float(act))\n",
    "                except:\n",
    "                    all_data[(tid, ikey)].append((int(doc_id), None, float(act), rel))\n",
    "                    values.append(float(act))\n",
    "            else:\n",
    "                try:\n",
    "                    all_data[(tid, ikey)] = [(int(doc_id), int(year), float(act), rel)]\n",
    "                    values.append(float(act))\n",
    "                except:\n",
    "                    all_data[(tid, ikey)] = [(int(doc_id), None, float(act), rel)]\n",
    "                    values.append(float(act))\n",
    "            if ikey not in unique_ikey_smiles:\n",
    "                unique_ikey_smiles.update({ikey: smi})\n",
    "\n",
    "# iterate through the values in each pair\n",
    "# Used median to reduce the importance of outliers. In the case of an even number, it just takes the mean anyways.\n",
    "consensus = {key: None for key in all_data.keys()}\n",
    "\n",
    "for key, value in all_data.iteritems():\n",
    "    # get the median value of binding affinity\n",
    "    act = np.median(np.asarray([i[2] for i in value]))\n",
    "    # get the mode of the relation value\n",
    "    rel = mode(np.asarray([i[3] for i in value]))\n",
    "    # get the min year\n",
    "    try:\n",
    "        year = np.min(np.asarray([i[1] for i in value if i is not None]))\n",
    "    except:\n",
    "        year = 0\n",
    "    consensus[key] = (act, rel[0][0], year)\n",
    "\n",
    "# only accept targets with at least 10 positive values\n",
    "# indexer\n",
    "targets_counts_above_10 = {k: v for (k, v) in targets_counts.items() if v >= 10}\n",
    "target_pos_count = {k: 0 for k in targets_counts_above_10}\n",
    "\n",
    "# key[0] = target ; key[1] = molecule\n",
    "# value [0] = act ; value[1] = rel ; value[2] = year\n",
    "for key, value in consensus.items():\n",
    "    if convert_to_pki(value[0]) > cutoff:\n",
    "        try: \n",
    "            target_pos_count[key[0]] += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "final_target_set = {k for k, v in target_pos_count.items() if v >= 10}\n",
    "\n",
    "# create lookup table for what positon in the array corresponds to which target\n",
    "# ran once, for generation now, use saved target index for consistency\n",
    "target_index_outfile = \"{}/{}_target_index.pkl\".format(out_dir, output_base_name)\n",
    "target_index = {}\n",
    "count = 0\n",
    "for target in final_target_set:\n",
    "    target_index.update({target: count})\n",
    "    count += 1\n",
    "with open(target_index_outfile, 'wb') as tout:\n",
    "    pkl.dump(target_index, tout)\n",
    "\n",
    "bad_molecules = {k for k, v in fp_lookup_dict.items() if v.size == 0}\n",
    "consensus_minus_bad = {k: v for k, v in consensus.items() if k[1] not in bad_molecules and k[0] in target_index}\n",
    "print(\"Bad training cases removed: %d\" % (len(consensus) - len(consensus_minus_bad)))\n",
    "\n",
    "tmp_fp, tmp_act, tmp_pos, tmp_year, multi_task_lookup = write_onemol_onetarget_format(consensus_minus_bad, fp_lookup_dict, target_index, \"{}/{}\".format(out_dir, output_base_name), fp_len, cutoff=cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chembl20_MWmax800_scrubDM_minpos10_cutoff5_1midtomanytid.hdf5\r\n",
      "chembl20_MWmax800_scrubDM_minpos10_cutoff5_onetomany_ikey_lookup_file.pkl\r\n",
      "chembl20_MWmax800_scrubDM_minpos10_cutoff5_target_index.pkl\r\n",
      "make_hdf5.log\r\n"
     ]
    }
   ],
   "source": [
    "!ls $expt_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = \"{}/time_split\".format(expt_base)\n",
    "bv_type = \"4096\"\n",
    "CUTOFF_YEAR = 2012\n",
    "fp_len=int(bv_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output files\n",
    "in_h5py = \"{}/chembl20_MWmax800_scrubDM_minpos10_cutoff5_1midtomanytid.hdf5\".format(expt_base)\n",
    "in_target_index = \"{}/chembl20_MWmax800_scrubDM_minpos10_cutoff5_target_index.pkl\".format(expt_base)\n",
    "\n",
    "\n",
    "val_hdf5= \"{}/val_chembl20_MWmax800_scrubDM_minpos10_cutoff5_1midtomanytid_fplen{}_TS{}.hdf5\".format(out_dir, bv_type, CUTOFF_YEAR)\n",
    "train_hdf5 = \"{}/train_chembl20_MWmax800_scrubDM_minpos10_cutoff5_1midtomanytid_fplen{}_TS{}.hdf5\".format(out_dir, bv_type, CUTOFF_YEAR)\n",
    "in_target_index = \"{}/chembl20_MWmax800_scrubDM_minpos10_cutoff5_fplen{}_TS{}_target_index.pkl\".format(expt_base, bv_type, CUTOFF_YEAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 4096)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "# read data to arrays\n",
    "with h5py.File(in_h5py, 'r') as h:\n",
    "    act_arr = h[\"activity\"][:].copy()\n",
    "    fp_arr = h[\"fp_array\"][:].copy()\n",
    "    pos_arr =  h[\"position\"][:].copy()\n",
    "    year_arr = h[\"year\"][:].copy()\n",
    "    print np.shape(act_arr)\n",
    "    print np.shape(fp_arr)\n",
    "    print np.shape(pos_arr)\n",
    "    print np.shape(year_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 550.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'CHEMBL1075145'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-22b48defe5d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CHEMBL1075145'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'CHEMBL1075145'"
     ]
    }
   ],
   "source": [
    "str(int('CHEMBL1075145'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"CHEMBL181880\" in new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_test = {i[1] for i in unique_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'CHEMBL181880' in set(ikey_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gzip.open(mid2inchi, \"rb\") as f:\n",
    "    # store molecules in case we want to go back and look them up.\n",
    "    ikey_map = pkl.load(f)\n",
    "ikey_map = ikey_map.set_index(\"index\").to_dict()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chembl_df = pd.read_csv(raw_chembl_name, sep=\"\\t\", compression=\"gzip\", index_col=0)\n",
    "tmp_df = chembl_df.groupby([\"ChEMBL_Target_ID\", \"ChEMBL_Molecule_ID\"]).size().reset_index().rename(columns={0:'count'})\n",
    "unique_pairs = { (i.ChEMBL_Target_ID, i.ChEMBL_Molecule_ID) for i in tmp_df.itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chembl_df = pd.read_csv(raw_chembl_name, sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: ChEMBL_Target_ID\n"
     ]
    }
   ],
   "source": [
    "unique_pairs = set()\n",
    "with gzip.open(raw_chembl_name, \"rb\") as f:\n",
    "    a = f.next()\n",
    "    vals = a.split(\"\\t\")\n",
    "    print(\"{}: {}\".format(vals[2], vals[3]))\n",
    "    for line in f:\n",
    "        # tid:mid\n",
    "        unique_pairs.update({(line.split(\"\\t\")[2], line.split(\"\\t\")[3])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading inchi to mid map\n"
     ]
    }
   ],
   "source": [
    "print(\"loading inchi to mid map\")\n",
    "with gzip.open(mid2inchi, \"rb\") as f:\n",
    "    # store molecules in case we want to go back and look them up.\n",
    "    ikey_map = pkl.load(f)\n",
    "ikey_map = ikey_map.set_index(\"index\").to_dict()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = get_env_var(\"DATA_SAVE_BASE\")\n",
    "expt_base = \"{}/20180525_DM_scrubbing\".format(base)\n",
    "raw_chembl_name = \"{}/raw_data/full_chembl20_cutoff800_dm_scrubbed.csv.gz\".format(expt_base)\n",
    "smiles = \"{}/raw_data/all_chembl_smiles_mid_mwcutoff800.smi\".format(expt_base)\n",
    "inchi_dict=\"{}/raw_data/chembl20_MWmax800_smiles2inchi2mid.csv.gz\".format(expt_base)\n",
    "inchi2smiles = \"{}/raw_data/inchi2smiles.csv.gz\".format(expt_base)\n",
    "mid2inchi = \"{}/raw_data/mid2inchi.csv.gz\".format(expt_base)\n",
    "\n",
    "out_base = \"{}/train_data\".format(expt_base)\n",
    "output_base_name = \"chembl20_MWmax800_scrubDM_minpos10_cutoff5\"\n",
    "fp_file = \"{}/raw_data/chembl20_MWmax800_fps.fp.gz\".format(expt_base)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
