{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Purpose: Deterimine time-splits for our training sets and write them to file.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "__author__ = \"Elena Caceres\"\n",
    "__email__ = \"ecaceres@keiserlab.org\"\n",
    "\"\"\"Purpose: Deterimine time-splits for our training sets and write them to file.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/ecaceres/anaconda2/envs/features/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "from common.data_converter import convert_to_pki\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_env_var(handle):\n",
    "    tmp = os.getenv(handle)\n",
    "    if not tmp:\n",
    "        raise LookupError(\"Environment variable: {} not set.\".format(handle))\n",
    "    return tmp.strip(\"'\")\n",
    "\n",
    "\n",
    "# what are the new valid targets? Get rid of targets with <10pos ligands\n",
    "def get_targets_with_count(positions, affinities, query_idxes, num_pos=10, affinity_cutoff=5.0):\n",
    "    \"\"\"Given positions\"\"\"\n",
    "    tmp_pos = positions[query_idxes]\n",
    "    tmp_aff = convert_to_pki(affinities[query_idxes])\n",
    "    \n",
    "    pos_counts = {i:0 for i in set(tmp_pos)}\n",
    "    # get column counts for each target above the cutoff\n",
    "    for target, value in zip(tmp_pos, tmp_aff):\n",
    "        if value and value > affinity_cutoff:\n",
    "            pos_counts[target] += 1\n",
    "    return {k for k,v in pos_counts.iteritems() if v > num_pos-1}\n",
    "\n",
    "\n",
    "def target_reindexer(targs):\n",
    "    return {k: v for v, k in enumerate(targs)}\n",
    "\n",
    "\n",
    "def make_new_tid_index_map(orig_tid_index_file, reindexed_targs, save_name=None):\n",
    "    # load target index and create a new pkl with the mapping for later\n",
    "    with open(orig_tid_index_file, 'rb') as t:\n",
    "            orig = pkl.load(t)\n",
    "    rv_orig = {v:k for k,v in orig.iteritems()}\n",
    "    new_targ_map = {rv_orig[k]:v for k,v in reindexed_targs.iteritems()}\n",
    "    if save_name:\n",
    "        # store new target index\n",
    "        with open(save_name, 'wb') as o:\n",
    "                pkl.dump(new_targ_map, o)\n",
    "    return new_targ_map\n",
    "\n",
    "\n",
    "def load_hdf5_data(in_file):\n",
    "    with h5py.File(in_file, 'r') as h:\n",
    "        act = h[\"activity\"][:].copy()\n",
    "        fp = h[\"fp_array\"][:].copy()\n",
    "        pos =  h[\"position\"][:].copy()\n",
    "        year = h[\"year\"][:].copy()\n",
    "        rel = h[\"rel_array\"][:].copy()\n",
    "    return act, fp, pos, year, rel\n",
    "\n",
    "\n",
    "# make numpy arrays to write\n",
    "def make_empty_arrays(num_mols, max_examples):\n",
    "    act = np.full((num_mols, max_examples), np.nan, dtype = np.float32)\n",
    "    pos = np.full((num_mols, max_examples), np.nan, dtype = np.uint16)\n",
    "    rel = np.full((num_mols, max_examples), np.nan, dtype = \"S1\")\n",
    "    year = np.zeros((num_mols, max_examples), dtype = np.uint16)\n",
    "    return act, pos, rel, year\n",
    "\n",
    "\n",
    "def get_masks(idxes, target_mask):\n",
    "    example_counter = np.sum(idxes, axis=1)\n",
    "    columns_needed = example_counter.max()\n",
    "    # Remove any molecules that no longer have examples\n",
    "    good_fps = example_counter > 0\n",
    "    # given initial good indexes, targets of interest, and molecules with >0 examples\n",
    "    good_fps_repeat = good_fps.reshape((-1,1)).repeat(target_mask.shape[1], axis=1)\n",
    "    total_mask = target_mask & idxes & good_fps_repeat\n",
    "    # get the number of molecules needed to represent data in h5py with new mask\n",
    "    good_fps = np.sum(total_mask, axis=1)>0\n",
    "    num_cols = np.sum(total_mask, axis=1).max()\n",
    "    num_fps = good_fps.sum()\n",
    "    return num_fps, num_cols, good_fps, total_mask\n",
    "\n",
    "\n",
    "def make_arrays(num_fps, num_cols, mask, fp_mask, act_arr, fp_arr, pos_arr, year_arr, rel_arr, old_pos_to_new_pos):\n",
    "    new_act, new_pos, new_rel, new_year = make_empty_arrays(num_fps, num_cols)\n",
    "    new_fp = fp_arr[fp_mask]\n",
    "    row_counter = 0\n",
    "    # given the good molecules AND the train indices, move values around.\n",
    "    for idx in np.arange(0, mask.shape[0], 1):\n",
    "        row_mask = mask[idx]\n",
    "        activities = act_arr[idx][row_mask]\n",
    "        positions = [old_pos_to_new_pos[i] for i in pos_arr[idx][row_mask]]\n",
    "        relations = rel_arr[idx][row_mask]\n",
    "        years = year_arr[idx][row_mask]\n",
    "        num_values = len(activities)\n",
    "        assert(num_values == len(positions) == len(relations) == len(years))\n",
    "        if num_values > 0:\n",
    "            np.put(new_act[row_counter], range(num_values), activities)\n",
    "            np.put(new_pos[row_counter], range(num_values), positions)\n",
    "            np.put(new_rel[row_counter], range(num_values), relations)\n",
    "            np.put(new_year[row_counter], range(num_values), years)\n",
    "            row_counter += 1       \n",
    "    return new_fp, new_act, new_pos, new_rel, new_year\n",
    "\n",
    "def save_h5py(save_name, num_targets, tmp_fp_arr, tmp_act, tmp_pos, tmp_rel, tmp_year, desc=\"\"):\n",
    "        with h5py.File(save_name, 'w') as f:\n",
    "            \n",
    "            # pre-allocate arrays for our dataset\n",
    "            num_fps = tmp_fp_arr.shape[0]\n",
    "            fp_len = tmp_fp_arr.shape[1]\n",
    "            max_cols = tmp_act.shape[1]\n",
    "            \n",
    "            fp_arr = f.create_dataset('fp_array', (num_fps, fp_len), dtype=np.bool, chunks=True, fillvalue=False, compression=\"lzf\")\n",
    "            act_arr = f.create_dataset('activity', (num_fps, max_cols), dtype=np.float32, chunks=True, fillvalue=0.0, compression=\"lzf\")\n",
    "            pos_arr = f.create_dataset('position', (num_fps, max_cols), dtype=np.uint16, chunks=True, fillvalue=0, compression=\"lzf\")\n",
    "            rel_arr = f.create_dataset('relation', (num_fps, max_cols), dtype=\"S1\", chunks=True, fillvalue='', compression=\"lzf\")\n",
    "            year_arr = f.create_dataset('year', (num_fps, max_cols), dtype=np.uint16, chunks=True, fillvalue=0, compression=\"lzf\")\n",
    "\n",
    "            # set values\n",
    "            fp_arr[:] = tmp_fp_arr\n",
    "            act_arr[:] = tmp_act\n",
    "            pos_arr[:] = tmp_pos\n",
    "            rel_arr[:] = tmp_rel\n",
    "            year_arr[:] = tmp_year\n",
    "\n",
    "            # declare attributes for meta-data\n",
    "            f.attrs[\"activity_units\"] = \"nM, median\"\n",
    "            f.attrs[\"relationship_type\"] = \"mode\"\n",
    "            f.attrs[\"year_type\"]=\"First publication date. If None given, value = 0\"\n",
    "            f.attrs[\"training_cases\"] = num_fps\n",
    "            f.attrs[\"fprint_len\"] = fp_len\n",
    "            f.attrs[\"num_targets\"] = num_targets\n",
    "            f.attrs[\"fprint_type\"] = \"bit/ECFP4\"\n",
    "            f.attrs[\"desc\"] = desc\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for mk-1-a server\n",
    "# SAVE_IMAGE_DIR=\"/srv/home/ecaceres/labgits/lab-notebook-caceres.wiki/images/20160328-Time-Split-Info\"\n",
    "\n",
    "# update save image dir for new positive:negative ligand cutoff:\n",
    "base = get_env_var(\"DATA_SAVE_BASE\")\n",
    "expt_base = \"{}/20180525_DM_scrubbing/train_data\".format(base)\n",
    "bv_type = \"4096\"\n",
    "CUTOFF_YEAR = 2012\n",
    "fp_len=int(bv_type)\n",
    "\n",
    "# # output files\n",
    "in_h5py = \"{}/chembl20_MWmax800_scrubDM_minpos10_cutoff5.hdf5\".format(expt_base)\n",
    "in_target_index = \"{}/chembl20_MWmax800_scrubDM_minpos10_cutoff5_target_index.pkl\".format(expt_base)\n",
    "\n",
    "val_hdf5 = \"{}/val_ts2012_chembl20_MWmax800_scrubDM_minpos10_cutoff5.hdf5\".format(expt_base)\n",
    "train_hdf5 = \"{}/train_ts2012_chembl20_MWmax800_scrubDM_minpos10_cutoff5.hdf5\".format(expt_base)\n",
    "out_target_index = \"{}/ts2012_chembl20_MWmax800_scrubDM_minpos10_cutoff5_target_index.pkl\".format(expt_base)# read data to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_arr, fp_arr, pos_arr, year_arr, rel_arr = load_hdf5_data(in_h5py)\n",
    "\n",
    "# indexes with a value in them\n",
    "valid_idxes = ~np.isnan(act_arr)\n",
    "\n",
    "# indexes where the year is < 2012\n",
    "year_lt_2012 = year_arr<CUTOFF_YEAR\n",
    "\n",
    "# new train and test masks. \n",
    "#new_val_idxes ~1/5 of new_train indexes confirmed.\n",
    "new_train_idxes = valid_idxes & year_lt_2012\n",
    "new_val_idxes = valid_idxes & ~year_lt_2012\n",
    "\n",
    "# get counts of targets with >=10 positive ligands\n",
    "targs_to_use = get_targets_with_count(pos_arr, act_arr, new_train_idxes)\n",
    "# give new positions to those targets\n",
    "old_pos_to_new_pos = target_reindexer(targs_to_use)\n",
    "# make a new map of those positions and save it\n",
    "targ_reindex = make_new_tid_index_map(in_target_index, old_pos_to_new_pos, save_name=out_target_index)\n",
    "# get a mask for the positons we'd like to keep based on the target & valid indexes in general\n",
    "valid_pos = [k for k in old_pos_to_new_pos.keys()]\n",
    "# target mask where there is data stored and where the targets are in our new dataset.\n",
    "target_mask = np.isin(pos_arr, valid_pos) & valid_idxes\n",
    "\n",
    "# get masks and good fingerprints to write\n",
    "num_train_fps, num_train_cols, train_fp_mask, train_mask = get_masks(new_train_idxes, target_mask)\n",
    "num_val_fps, num_val_cols, val_fp_mask, val_mask = get_masks(new_val_idxes, target_mask)\n",
    "\n",
    "# get actual training arrays\n",
    "train_fp_arr, train_act_arr, train_pos_arr, train_rel_arr, train_year_arr = make_arrays(num_train_fps, num_train_cols, train_mask, train_fp_mask, act_arr, fp_arr, pos_arr, year_arr, rel_arr, old_pos_to_new_pos)\n",
    "val_fp_arr, val_act_arr, val_pos_arr, val_rel_arr, val_year_arr = make_arrays(num_val_fps, num_val_cols, val_mask, val_fp_mask, act_arr, fp_arr, pos_arr, year_arr, rel_arr, old_pos_to_new_pos)\n",
    "\n",
    "# save data\n",
    "num_targets = len(targ_reindex)\n",
    "desc = \"TS 2012 {} data for ECFP multi-task network with DM scrubbed and no PCBA. 10 positive ligands/target with a cutoff of pac50 of 5.0.  See lookup tables for target indexing\"\n",
    "save_h5py(train_hdf5, num_targets, train_fp_arr, train_act_arr, train_pos_arr, train_rel_arr, train_year_arr, \n",
    "          desc=desc.format(\"Train\"))\n",
    "save_h5py(val_hdf5, num_targets, val_fp_arr, val_act_arr, val_pos_arr, val_rel_arr, val_year_arr, \n",
    "          desc=desc.format(\"Validation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
