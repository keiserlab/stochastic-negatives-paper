{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "from itertools import chain\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_env_var(handle):\n",
    "    ''' Get an environment variable given the handle for the bash variable'''\n",
    "    tmp = os.getenv(handle)\n",
    "    if not tmp:\n",
    "        raise LookupError(\"Environment variable: {} not set.\".format(handle))\n",
    "    return tmp.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss_df(loss_file):\n",
    "    df = pd.read_csv(loss_file, header=None, names=[\"loss\"])\n",
    "    df = df.reset_index()\n",
    "    df.columns = [\"epoch\", \"loss\"]\n",
    "    return df\n",
    "\n",
    "def find_nearest_epoch(array, value, n=5):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    \n",
    "    return array[idx]\n",
    "    \n",
    "class  Experiment(dict):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.folds = []\n",
    "        self.converged_epochs = []\n",
    "        self.trained_paths = []\n",
    "      \n",
    "    def __repr__(self):\n",
    "        return str(vars(self))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return json.dumps(vars(self), indent=2)\n",
    "        \n",
    "    def set_convereged_epoch(self, epoch, train_path, fold=None):        \n",
    "        self.folds.append(fold)\n",
    "        self.converged_epochs.append(epoch)\n",
    "        self.trained_paths.append(train_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_losses(train_base):\n",
    "    loss_fmter=\"{}_loss.csv\"\n",
    "    train_loss_file = \"{}/{}\".format(train_base, loss_fmter.format(\"train\"))\n",
    "    test_loss_file = \"{}/{}\".format(train_base, loss_fmter.format(\"test\"))\n",
    "    test_loss = get_loss_df(test_loss_file)\n",
    "    train_loss = get_loss_df(train_loss_file)\n",
    "    return test_loss, train_loss\n",
    "\n",
    "\n",
    "def get_best_epochs(train_base):\n",
    "    \"\"\"get best epoch weight file given list of test_loss, train_loss, and \n",
    "    a train base for the weights\"\"\"\n",
    "    test_loss, train_loss = load_losses(train_base)\n",
    "    expt = train_base.split(\"trained_nets/\")[-1]\n",
    "    weights_files = glob.glob(\"{}/model_at_epoch_*.npz\".format(train_base))\n",
    "    # take the minimum test loss\n",
    "    min_test = np.min(test_loss[\"loss\"])\n",
    "    # get the values there for test and train\n",
    "    test_epoch, test_value = test_loss[test_loss[\"loss\"] == min_test].values[0]\n",
    "    train_epoch, train_value = train_loss[train_loss[\"epoch\"] == test_epoch].values[0]\n",
    "    # sort available weight files\n",
    "    file_epochs = [int(n.split(\"_\")[-1].split(\".\")[0]) for n in weights_files]\n",
    "    sorted_epochs = sorted(zip((test_loss[\"loss\"] - test_value), test_loss[\"epoch\"]), \n",
    "                           key=lambda x: x[0], reverse=False)\n",
    "    best_epochs = [g for g in sorted_epochs if g[1] in file_epochs]\n",
    "    best_value, best_epoch = best_epochs[0]\n",
    "    curr_test_val = test_loss[test_loss[\"epoch\"]==best_epoch].loss.values[0]\n",
    "    return_weights = [i for i in weights_files if \"_{}.npz\".format(int(best_epoch)) in i][0]\n",
    "    \n",
    "    return best_epoch, curr_test_val, return_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAVE_BASE = get_env_var(\"DATA_SAVE_BASE\")\n",
    "model_base = \"{}/20190410_SMA_Investigation/trained_nets/*\".format(SAVE_BASE)\n",
    "loss_fmter=\"{}_loss.csv\"\n",
    "dirs = glob.glob(\"{}/*/fold_*/\".format(model_base))\n",
    "subdirs = [glob.glob(\"{}/pnr_*\".format(d)) for d in dirs]\n",
    "subdirs.append(d for d in dirs if len(glob.glob(\"{}/pnr_*\".format(d)))==0)\n",
    "subdirs = list(chain.from_iterable(subdirs))\n",
    "subdirs = sorted(subdirs)\n",
    "names = set(i.split(\"trained_nets/\")[-1].split(\"/\")[1] for i in subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test or train loss file for /srv/nas/mk1/users/ecaceres//20190410_SMA_Investigation/trained_nets/lr_nesterov_binary_classifier_1024_2048_3072/CLASSIFIER_SMA_RATIOS_scrambled_LR01/fold_0/pnr_19.0\n",
      "No test or train loss file for /srv/nas/mk1/users/ecaceres//20190410_SMA_Investigation/trained_nets/lr_nesterov_binary_classifier_1024_2048_3072/CLASSIFIER_SMA_RATIOS_scrambled_LR03/fold_0/pnr_0.25\n"
     ]
    }
   ],
   "source": [
    "expt_dict = {n:[] for n in names}\n",
    "\n",
    "for k, v in expt_dict.items():\n",
    "    tmp_dirs = set(i for i in subdirs if \"/{}/\".format(k) in i)\n",
    "    # get all unique pnrs per expt\n",
    "    unique_pnrs = set(i.split(\"/\")[-1] for i in tmp_dirs if \"pnr_\" in i)\n",
    "    \n",
    "    if len(unique_pnrs) > 0:\n",
    "        for curr_pnr in unique_pnrs:\n",
    "            expt_name = \"{}_{}\".format(k, curr_pnr)\n",
    "            exp = Experiment(expt_name)\n",
    "            tmp_dir_subset =  [i for i in tmp_dirs if curr_pnr in i]\n",
    "            tmp_dir_subset = sorted(tmp_dir_subset)\n",
    "            for d in tmp_dir_subset:\n",
    "                train_base = d\n",
    "                fold = d.split(\"/\")[-2]\n",
    "                try:\n",
    "                    b_e, b_v, returned_weights = get_best_epochs(train_base)\n",
    "                    exp.set_convereged_epoch(b_e, d, fold)\n",
    "                    \n",
    "                except IOError:\n",
    "                    print(\"No test or train loss file for {}\".format(train_base))\n",
    "            expt_dict[k].append(exp)\n",
    "    else:\n",
    "        curr_pnr = None\n",
    "        expt_name = \"{}\".format(k)\n",
    "        exp = Experiment(expt_name)\n",
    "        tmp_dir_subset = sorted(tmp_dirs)\n",
    "        for d in tmp_dir_subset:\n",
    "                train_base = d\n",
    "                fold = d.split(\"/\")[-2]\n",
    "                try:\n",
    "                    b_e, b_v, returned_weights = get_best_epochs(train_base)\n",
    "                    exp.set_convereged_epoch(b_e, d, fold)\n",
    "                    \n",
    "                except IOError:\n",
    "                    print(\"No test or train loss file for {}\".format(train_base))\n",
    "        expt_dict[k].append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving experiments as json to:\n",
      "/srv/nas/mk1/users/ecaceres//20190410_SMA_Investigation/predictions/CLASSIFIER_NEG_RM_SMA_RATIOS_scrambled_LR03\n",
      "saving experiments as json to:\n",
      "/srv/nas/mk1/users/ecaceres//20190410_SMA_Investigation/predictions/NEG_RM_scrambled\n"
     ]
    }
   ],
   "source": [
    "outdir = \"{}/20190410_SMA_Investigation/predictions/{}\".format(SAVE_BASE, \"{}\")\n",
    "\n",
    "for k in expt_dict.keys():\n",
    "    json_dir = outdir.format(k)\n",
    "    if not os.path.exists(json_dir):\n",
    "        os.makedirs(json_dir)\n",
    "    experiment_epochs = expt_dict[k]\n",
    "    expt_json_name = os.path.join(json_dir, 'experiments.json')\n",
    "    if not os.path.exists(expt_json_name):\n",
    "        print(\"saving experiments as json to:\")\n",
    "        print(json_dir)\n",
    "        with open(expt_json_name, 'w') as fp:\n",
    "            json.dump([vars(e) for e in experiment_epochs], fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls /srv/nas/mk1/users/ecaceres//20190410_SMA_Investigation/predictions/NEG_RM_scrambled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_negs_stochastic_args.txt\r\n",
      "all_negs_stochastic_INFO.log\r\n",
      "model_at_epoch_0.npz\r\n",
      "model_at_epoch_100.npz\r\n",
      "model_at_epoch_13.npz\r\n",
      "model_at_epoch_200.npz\r\n",
      "model_at_epoch_25.npz\r\n",
      "model_at_epoch_300.npz\r\n",
      "model_at_epoch_400.npz\r\n",
      "model_at_epoch_499.npz\r\n",
      "test_indices.npy\r\n",
      "test_loss.csv\r\n",
      "test_loss.png\r\n",
      "test_no_gt_loss.csv\r\n",
      "test_no_gt_loss.png\r\n",
      "training_log.txt\r\n",
      "train_loss.csv\r\n",
      "train_loss.png\r\n",
      "ts2012_chembl20_MWmax800_scrubDM_minpos10_cutoff5_target_index.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls /srv/nas/mk1/users/ecaceres//20190410_SMA_Investigation/trained_nets/all_negs_stochastic/NEG_RM_scrambled/fold_4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "      276,\n",
    "      310,\n",
    "      293,\n",
    "      387,\n",
    "      349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \"converged_epochs\": [\n",
    "      300,\n",
    "      300,\n",
    "      300,\n",
    "      400,\n",
    "      300\n",
    "    ],\n",
    "    \"name\": \"NEG_RM_scrambled\",\n",
    "    \"trained_paths\": [\n",
    "      \"/srv/nas/mk1/users/ecaceres//20190410_SMA_Investigation/trained_nets/all_negs_stochastic/NEG_RM_scrambled/fold_0/\",\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
